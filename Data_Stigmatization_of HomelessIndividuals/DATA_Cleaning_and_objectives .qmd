---
title: "DATA_Cleaning_and_objectives "
---
# DATA Cleaning
I will use this document to clean the data for this project
#Data Cleaning steps 
```{r}
#Loading data and setting seed
```{r}
#| label: setup
library(tidyverse)
set.seed(1234)
```

```{r}

#| label: read- messy- data for project 

# Read in messy-midwest.csv with read_csv(). I folled the mini project instructions this was extremly helful when completeing this task.
messy.stigma <- read_csv("Data_Stigmatization_of HomelessIndividuals/Experimental_Study_Karen.csv")

  trim_ws = FALSE, name_repair = "minimal", col_types = cols(.default = col_character()))

# Inspect the structure and contents of the messy midwest dataset with head(), glimpse(), str(), and/or View()
head(messy.stigma)
glimpse(messy.stigma)
str(messy.stigma)
View(messy.stigma)

```
# what I see in the data
All the data is numerical and should not be. The labels for the data columns should be clearer and more descriptive.there is no distiniction between partipant demographics and the data collected.also have to make labels more consistent
## listing and organizaing the data. what were the variables and what do they represent 
```{r}
variable_names <- c(
  "IV1_race", "IV2_diagnosis", "condition", 
  "socialdistance_1", "socialdistance_2", "socialdistance_3",
  "blame_1", "blame_2", "blame_3", 
  "danger_1", "danger_2", "danger_3",
  "concern_1", "concern_2", "concern_3",
  "help_1", "help_2",
  "social_desirability",
  "memorycheck_race", "memorycheck_diagnosis",
  "gender", "age", "ethnicity", "political_affiliation", "homeless_familiarity"
)

descriptions <- c(
  "Participant's race condition in the vignette (1 = White, 2 = Black) [Nominal]",
  "Mental illness condition in the vignette (0 = No diagnosis, 1 = Substance use disorder, 2 = Schizophrenia) [Nominal]",
  "Experimental condition assigned (1–6 representing race x diagnosis combination) [Nominal]",
  
  "Social distance measure (higher = greater distance) - Item 1: 'How willing would you be to have Michael live in your community?' (1 = Completely unwilling to 7 = Completely willing) [Ordinal]",
  "Social distance measure (higher = greater distance) - Item 2 (1 = Completely unwilling to 7 = Completely willing) [Ordinal]",
  "Social distance measure (higher = greater distance) - Item 3 (1 = Completely unwilling to 7 = Completely willing) [Ordinal]",
  
  "Blame attribution score - Item 1: 'Do you think Michael is responsible for his situation?' (1 = Definitely No to 7 = Definitely Yes) [Ordinal]",
  "Blame attribution score - Item 2 (1 = Definitely No to 7 = Definitely Yes) [Ordinal]",
  "Blame attribution score - Item 3 (reverse-coded) (1 = Definitely No to 7 = Definitely Yes) [Ordinal]",
  
  "Perceived danger score - Item 1: 'Do you think Michael would be a danger to the community?' (1 = Definitely No to 7 = Definitely Yes) [Ordinal]",
  "Perceived danger score - Item 2 (1 = Definitely No to 7 = Definitely Yes) [Ordinal]",
  "Perceived danger score - Item 3 (1 = Definitely No to 7 = Definitely Yes) [Ordinal]",
  
  "Level of concern for the target (higher = less concern, more stigma) - Item 1: 'How much concern would you feel for Michael?' (1 = None at all to 7 = Very much) [Ordinal]",
  "Level of concern for the target (higher = less concern, more stigma) - Item 2 (1 = None at all to 7 = Very much) [Ordinal]",
  "Level of concern for the target (higher = less concern, more stigma) - Item 3 (1 = None at all to 7 = Very much) [Ordinal]",
  
  "Willingness to help score (higher = lower willingness, more stigma) - Item 1: 'How likely is it that you would talk to Michael if you saw him in the park?' (1 = Not likely at all to 7 = Very likely) [Ordinal]",
  "Willingness to help score (higher = lower willingness, more stigma) - Item 2 (1 = Not likely at all to 7 = Very likely) [Ordinal]",
  
  "Social desirability score (higher = greater tendency to respond in socially desirable ways) - Measured using the Marlowe-Crowne Social Desirability Scale (Reynolds, 1982). Example item: 'I’m always willing to admit when I make a mistake.' (0-13 scale) [Interval]",
  
  "Memory check: Recall of Michael's race/ethnicity (1 = Correct, 0 = Incorrect) [Nominal]",
  "Memory check: Recall of Michael's mental illness diagnosis (1 = Correct, 0 = Incorrect) [Nominal]",
  
  "Participant's gender (1 = Male, 2 = Female, 3 = Non-binary, 4 = Other) [Nominal]",
  "Participant's age in years (Open-ended numeric response) [Ratio]",
  "Participant's ethnicity (1 = Hispanic, 2 = Black, 3 = White, etc.) [Nominal]",
  "Political affiliation (1 = Conservative, 2 = Liberal, 3 = Moderate, etc.) [Nominal]",
  "Familiarity with homelessness (1 = Yes, 0 = No). Example: 'Have you ever observed, in passing, a person you believed to be homeless?' [Nominal]"
)

data_dictionary <- data.frame(Variable = variable_names, Description = descriptions)
print(data_dictionary)

```
# Making a clean data 
```{r}
#| label: make-cleaning-dataset

# Create a dataset to work with during the cleaning process
messy.stigma_cleaned <- messy.stigma
```

```{r}
#| label: inspect-column-names

# Check the names and order of columns in messy.midwest 
colnames(messy.stigma)
# Check the names and order of columns in midwest:
colnames(messy.stigma)
# Check the names and order of columns in messy.midwest_cleaned:
colnames(messy.stigma _cleaned)
```

```{r}
#| label: setup
library(tidyverse)
set.seed(1234)
```

```{r}
# Select specific columns, rename them, and reorder if necessary
#only certain columns needed fixing 
messy.stigma_cleaned <- messy.stigma %>%
rename(Race_Condition = `IV1_race`, 
         Diagnosis_Condition = `IV2_diagnosis`, 
         Condition_Type = `condition`, 
         Social_Distance_Score_1 = `socialdistance_1`, 
         Social_Distance_Score_2 = `socialdistance_2`, 
         Social_Distance_Score_3 = `socialdistance_3`, 
         Blame_Attribution_1 = `blame_1`, 
         Blame_Attribution_2 = `blame_2`, 
         Blame_Attribution_3 = `blame_3`, 
         Perceived_Danger_1 = `danger_1`, 
         Perceived_Danger_2 = `danger_2`, 
         Perceived_Danger_3 = `danger_3`, 
         Concern_About_Impact_1 = `concern_1`, 
         Concern_About_Impact_2 = `concern_2`, 
         Concern_About_Impact_3 = `concern_3`, 
         Help_Offering_1 = `help_1`, 
         Help_Offering_2 = `help_2`, 
         Gender_Participant = `gender`, 
         Age_of_Participant = `age`, 
         Ethnicity_Participant = `ethnicity`, 
         Community_Type = `community`, 
         Political_Affiliation = `political_affiliation`, 
         Previous_Contact_with_Homeless_Population = `contact_homeless`, 
         Social_Desirability_Bias = `social_desirability`, 
         Reverse_Social_Distance_1 = `socialdistanceR1`, 
         Reverse_Social_Distance_2 = `socialdistanceR2`, 
         Reverse_Social_Distance_3 = `socialdistanceR3`, 
         Mean_Social_Distance = `Distance_mean`, 
         Reverse_Blaming_3 = `blameR3`, 
         Mean_Blaming_Attribution = `Blamemean`, 
         Mean_Perceived_Danger = `danger_mean`, 
         Reverse_Concern_1 = `concernR1`, 
         Reverse_Concern_2 = `ConcernR2`, 
         Reverse_Concern_3 = `ConcernR3`, 
         Mean_Concern_About_Impact = `Concern_mean`, 
         Reverse_Help_Offering_1 = `helpR1`, 
         Reverse_Help_Offering_2 = `helpR2`, 
         Mean_Help_Offering = `Help_Mean`)
```

## Changing data names
```{r}
# check current changes 
head(messy.stigma_cleaned)
colnames(messy.stigma_cleaned) # names were clearer and made more sense 
```
# changing the data types
```{r}
# Check current data types
str(messy.stigma)
```

```{r}
# Changing column types 
messy.stigma_cleaned <- messy.stigma_cleaned %>%
mutate(
    Race_Condition = as.factor(Race_Condition),
    Diagnosis_Condition = as.factor(Diagnosis_Condition),
    Condition_Type = as.factor(Condition_Type),
    Social_Distance_Score_1 = as.numeric(Social_Distance_Score_1),
    Social_Distance_Score_2 = as.numeric(Social_Distance_Score_2),
    Social_Distance_Score_3 = as.numeric(Social_Distance_Score_3),
    Blame_Attribution_1 = as.numeric(Blame_Attribution_1),
    Blame_Attribution_2 = as.numeric(Blame_Attribution_2),
    Blame_Attribution_3 = as.numeric(Blame_Attribution_3),
    Perceived_Danger_1 = as.numeric(Perceived_Danger_1),
    Perceived_Danger_2 = as.numeric(Perceived_Danger_2),
    Perceived_Danger_3 = as.numeric(Perceived_Danger_3),
    Concern_About_Impact_1 = as.numeric(Concern_About_Impact_1),
    Concern_About_Impact_2 = as.numeric(Concern_About_Impact_2),
    Concern_About_Impact_3 = as.numeric(Concern_About_Impact_3),
    Help_Offering_1 = as.numeric(Help_Offering_1),
    Help_Offering_2 = as.numeric(Help_Offering_2),
    Gender_Participant = as.factor(Gender_Participant),
    Age_of_Participant = as.numeric(Age_of_Participant),
    Ethnicity_Participant = as.factor(Ethnicity_Participant),
    Community_Type = as.factor(Community_Type),
    Political_Affiliation = as.factor(Political_Affiliation),
    Previous_Contact_with_Homeless_Population = as.factor(Previous_Contact_with_Homeless_Population),
    Social_Desirability_Bias = as.numeric(Social_Desirability_Bias),
    Reverse_Social_Distance_1 = as.numeric(Reverse_Social_Distance_1),
    Reverse_Social_Distance_2 = as.numeric(Reverse_Social_Distance_2),
    Reverse_Social_Distance_3 = as.numeric(Reverse_Social_Distance_3),
    Mean_Social_Distance = as.numeric(Mean_Social_Distance),
    Reverse_Blaming_3 = as.numeric(Reverse_Blaming_3),
    Mean_Blaming_Attribution = as.numeric(Mean_Blaming_Attribution),
    Mean_Perceived_Danger = as.numeric(Mean_Perceived_Danger),
    Reverse_Concern_1 = as.numeric(Reverse_Concern_1),
    Reverse_Concern_2 = as.numeric(Reverse_Concern_2),
    Reverse_Concern_3 = as.numeric(Reverse_Concern_3),
    Mean_Concern_About_Impact = as.numeric(Mean_Concern_About_Impact),
    Reverse_Help_Offering_1 = as.numeric(Reverse_Help_Offering_1),
    Reverse_Help_Offering_2 = as.numeric(Reverse_Help_Offering_2),
    Mean_Help_Offering = as.numeric(Mean_Help_Offering)
  )

# Check the data structure again to confirm changes
str(messy.stigma_cleaned)
```

#deleting data that is missing 
```{r}
#| label: other-cleaning
messy.stigma_cleaned <- messy.stigma_cleaned %>%
  drop_na() # remove rows with missing values
```
#removed any duplicated rows
```{r}
messy.stigma_cleaned <- messy.stigma_cleaned %>%
distinct() # removed any duplicated rows 
```

# Pipeline for cleaning data
```{r}
#| label: setup
library(tidyverse)
set.seed(1234)

# Create a cleaned dataset from the original dataset
messy.stigma_cleaned <- messy.stigma %>%
  # Rename columns for clarity
  rename(Race_Condition = `IV1_race`, 
         Diagnosis_Condition = `IV2_diagnosis`, 
         Condition_Type = `condition`, 
         Social_Distance_Score_1 = `socialdistance_1`, 
         Social_Distance_Score_2 = `socialdistance_2`, 
         Social_Distance_Score_3 = `socialdistance_3`, 
         Blame_Attribution_1 = `blame_1`, 
         Blame_Attribution_2 = `blame_2`, 
         Blame_Attribution_3 = `blame_3`, 
         Perceived_Danger_1 = `danger_1`, 
         Perceived_Danger_2 = `danger_2`, 
         Perceived_Danger_3 = `danger_3`, 
         Concern_About_Impact_1 = `concern_1`, 
         Concern_About_Impact_2 = `concern_2`, 
         Concern_About_Impact_3 = `concern_3`, 
         Help_Offering_1 = `help_1`, 
         Help_Offering_2 = `help_2`, 
         Gender_Participant = `gender`, 
         Age_of_Participant = `age`, 
         Ethnicity_Participant = `ethnicity`, 
         Community_Type = `community`, 
         Political_Affiliation = `political_affiliation`, 
         Previous_Contact_with_Homeless_Population = `contact_homeless`, 
         Social_Desirability_Bias = `social_desirability`, 
         Reverse_Social_Distance_1 = `socialdistanceR1`, 
         Reverse_Social_Distance_2 = `socialdistanceR2`, 
         Reverse_Social_Distance_3 = `socialdistanceR3`, 
         Mean_Social_Distance = `Distance_mean`, 
         Reverse_Blaming_3 = `blameR3`, 
         Mean_Blaming_Attribution = `Blamemean`, 
         Mean_Perceived_Danger = `danger_mean`, 
         Reverse_Concern_1 = `concernR1`, 
         Reverse_Concern_2 = `ConcernR2`, 
         Reverse_Concern_3 = `ConcernR3`, 
         Mean_Concern_About_Impact = `Concern_mean`, 
         Reverse_Help_Offering_1 = `helpR1`, 
         Reverse_Help_Offering_2 = `helpR2`, 
         Mean_Help_Offering = `Help_Mean`) %>%
  # Change column types
  mutate(
    Race_Condition = as.factor(Race_Condition),
    Diagnosis_Condition = as.factor(Diagnosis_Condition),
    Condition_Type = as.factor(Condition_Type),
    Social_Distance_Score_1 = as.numeric(Social_Distance_Score_1),
    Social_Distance_Score_2 = as.numeric(Social_Distance_Score_2),
    Social_Distance_Score_3 = as.numeric(Social_Distance_Score_3),
    Blame_Attribution_1 = as.numeric(Blame_Attribution_1),
    Blame_Attribution_2 = as.numeric(Blame_Attribution_2),
    Blame_Attribution_3 = as.numeric(Blame_Attribution_3),
    Perceived_Danger_1 = as.numeric(Perceived_Danger_1),
    Perceived_Danger_2 = as.numeric(Perceived_Danger_2),
    Perceived_Danger_3 = as.numeric(Perceived_Danger_3),
    Concern_About_Impact_1 = as.numeric(Concern_About_Impact_1),
    Concern_About_Impact_2 = as.numeric(Concern_About_Impact_2),
    Concern_About_Impact_3 = as.numeric(Concern_About_Impact_3),
    Help_Offering_1 = as.numeric(Help_Offering_1),
    Help_Offering_2 = as.numeric(Help_Offering_2),
    Gender_Participant = as.factor(Gender_Participant),
    Age_of_Participant = as.numeric(Age_of_Participant),
    Ethnicity_Participant = as.factor(Ethnicity_Participant),
    Community_Type = as.factor(Community_Type),
    Political_Affiliation = as.factor(Political_Affiliation),
    Previous_Contact_with_Homeless_Population = as.factor(Previous_Contact_with_Homeless_Population),
    Social_Desirability_Bias = as.numeric(Social_Desirability_Bias),
    Reverse_Social_Distance_1 = as.numeric(Reverse_Social_Distance_1),
    Reverse_Social_Distance_2 = as.numeric(Reverse_Social_Distance_2),
    Reverse_Social_Distance_3 = as.numeric(Reverse_Social_Distance_3),
    Mean_Social_Distance = as.numeric(Mean_Social_Distance),
    Reverse_Blaming_3 = as.numeric(Reverse_Blaming_3),
    Mean_Blaming_Attribution = as.numeric(Mean_Blaming_Attribution),
    Mean_Perceived_Danger = as.numeric(Mean_Perceived_Danger),
    Reverse_Concern_1 = as.numeric(Reverse_Concern_1),
    Reverse_Concern_2 = as.numeric(Reverse_Concern_2),
    Reverse_Concern_3 = as.numeric(Reverse_Concern_3),
    Mean_Concern_About_Impact = as.numeric(Mean_Concern_About_Impact),
    Reverse_Help_Offering_1 = as.numeric(Reverse_Help_Offering_1),
    Reverse_Help_Offering_2 = as.numeric(Reverse_Help_Offering_2),
    Mean_Help_Offering = as.numeric(Mean_Help_Offering)
  ) %>%
  # Remove rows with missing values
  drop_na() %>%
  # Remove duplicated rows
  distinct()

# Write the cleaned dataset to a CSV file
write.csv(messy.stigma_cleaned, "cleaned_stigma_data.csv", row.names = FALSE)

# Check the final cleaned dataset
str(messy.stigma_cleaned)

```

# Data Analysis futher steps- this would be used for the data analysis section of the paper if proffessor wanted to look at how particpant demographics effected the intial results 
```{r}
# Load necessary libraries
library(dplyr)

# Load the dataset
data <- read.csv("Data_Stigmatization_of HomelessIndividuals/cleaned_stigma_data.csv")

# Convert relevant variables to factors or numeric
data <- data %>%
  mutate(
    Ethnicity_Participant = as.factor(Ethnicity_Participant),
    Diagnosis_Condition = as.factor(Diagnosis_Condition),
    Condition_Type = as.factor(Condition_Type),
    Social_Distance_Score_1 = as.numeric(Social_Distance_Score_1),
    Social_Distance_Score_2 = as.numeric(Social_Distance_Score_2),
    Social_Distance_Score_3 = as.numeric(Social_Distance_Score_3),
    Blame_Attribution_1 = as.numeric(Blame_Attribution_1),
    Blame_Attribution_2 = as.numeric(Blame_Attribution_2),
    Blame_Attribution_3 = as.numeric(Blame_Attribution_3),
    Perceived_Danger_1 = as.numeric(Perceived_Danger_1),
    Perceived_Danger_2 = as.numeric(Perceived_Danger_2),
    Perceived_Danger_3 = as.numeric(Perceived_Danger_3),
    Concern_About_Impact_1 = as.numeric(Concern_About_Impact_1),
    Concern_About_Impact_2 = as.numeric(Concern_About_Impact_2),
    Concern_About_Impact_3 = as.numeric(Concern_About_Impact_3),
    Help_Offering_1 = as.numeric(Help_Offering_1),
    Help_Offering_2 = as.numeric(Help_Offering_2),
    Gender_Participant = as.factor(Gender_Participant),
    Age_of_Participant = as.numeric(Age_of_Participant),
    Community_Type = as.factor(Community_Type),
    Political_Affiliation = as.factor(Political_Affiliation),
    Previous_Contact_with_Homeless_Population = as.factor(Previous_Contact_with_Homeless_Population),
    Social_Desirability_Bias = as.numeric(Social_Desirability_Bias),
    Reverse_Social_Distance_1 = as.numeric(Reverse_Social_Distance_1),
    Reverse_Social_Distance_2 = as.numeric(Reverse_Social_Distance_2),
    Reverse_Social_Distance_3 = as.numeric(Reverse_Social_Distance_3),
    Mean_Social_Distance = as.numeric(Mean_Social_Distance),
    Reverse_Blaming_3 = as.numeric(Reverse_Blaming_3),
    Mean_Blaming_Attribution = as.numeric(Mean_Blaming_Attribution),
    Mean_Perceived_Danger = as.numeric(Mean_Perceived_Danger),
    Reverse_Concern_1 = as.numeric(Reverse_Concern_1),
    Reverse_Concern_2 = as.numeric(Reverse_Concern_2),
    Reverse_Concern_3 = as.numeric(Reverse_Concern_3),
    Mean_Concern_About_Impact = as.numeric(Mean_Concern_About_Impact),
    Reverse_Help_Offering_1 = as.numeric(Reverse_Help_Offering_1),
    Reverse_Help_Offering_2 = as.numeric(Reverse_Help_Offering_2),
    Mean_Help_Offering = as.numeric(Mean_Help_Offering)
  )

# Running ANOVAs for each scale score with different demographic variables

# Social Distance Scores
anova_SD1 <- aov(Social_Distance_Score_1 ~ Ethnicity_Participant, data = data)
summary(anova_SD1)

anova_SD2 <- aov(Social_Distance_Score_2 ~ Diagnosis_Condition, data = data)
summary(anova_SD2)

anova_SD3 <- aov(Social_Distance_Score_3 ~ Condition_Type, data = data)
summary(anova_SD3)

# Blame Attribution
anova_BA1 <- aov(Blame_Attribution_1 ~ Gender_Participant, data = data)
summary(anova_BA1)

anova_BA2 <- aov(Blame_Attribution_2 ~ Ethnicity_Participant, data = data)
summary(anova_BA2)

# Perceived Danger
anova_PD1 <- aov(Perceived_Danger_1 ~ Age_of_Participant, data = data)
summary(anova_PD1)

anova_PD2 <- aov(Perceived_Danger_2 ~ Community_Type, data = data)
summary(anova_PD2)

# Concern About Impact
anova_Concern1 <- aov(Concern_About_Impact_1 ~ Political_Affiliation, data = data)
summary(anova_Concern1)

anova_Concern2 <- aov(Concern_About_Impact_2 ~ Previous_Contact_with_Homeless_Population, data = data)
summary(anova_Concern2)

# Help Offering
anova_Help1 <- aov(Help_Offering_1 ~ Social_Desirability_Bias, data = data)
summary(anova_Help1)

anova_Help2 <- aov(Help_Offering_2 ~ Gender_Participant, data = data)
summary(anova_Help2)

# Mean Social Distance
anova_Mean_SD <- aov(Mean_Social_Distance ~ Ethnicity_Participant, data = data)
summary(anova_Mean_SD)

# Mean Blaming Attribution
anova_Mean_BA <- aov(Mean_Blaming_Attribution ~ Ethnicity_Participant, data = data)
summary(anova_Mean_BA)

# Mean Perceived Danger
anova_Mean_PD <- aov(Mean_Perceived_Danger ~ Community_Type, data = data)
summary(anova_Mean_PD)

# Mean Concern About Impact
anova_Mean_Concern <- aov(Mean_Concern_About_Impact ~ Political_Affiliation, data = data)
summary(anova_Mean_Concern)

# Mean Help Offering
anova_Mean_Help <- aov(Mean_Help_Offering ~ Previous_Contact_with_Homeless_Population, data = data)
summary(anova_Mean_Help)

# Check assumptions of ANOVA
par(mfrow=c(2,2))
plot(anova_Mean_SD)
plot(anova_Mean_BA)
plot(anova_Mean_PD)
plot(anova_Mean_Concern)
```

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(RColorBrewer)

# Load the dataset
data <- read.csv("Data_Stigmatization_of HomelessIndividuals/cleaned_stigma_data.csv")

# Convert relevant variables to factors
data <- data %>%
  mutate(
    Ethnicity_Participant = factor(Ethnicity_Participant, 
                                    levels = c("White", "Hispanic", "Black", "Asian American", "Biracial", "Other"),
                                    labels = c("White", "Hispanic", "Black", "Asian American", "Biracial", "Other")),
    Gender_Participant = as.factor(Gender_Participant)
  )

# Gather the columns for the various measures into a long format
data_long <- data %>%
  gather(key = "Measure", value = "Score", 
         Social_Distance_Score_1, Blame_Attribution_1, Perceived_Danger_1, Concern_About_Impact_1, Help_Offering_1)

# Calculate mean for each measure and ethnicity
data_means <- data_long %>%
  group_by(Ethnicity_Participant, Measure) %>%
  summarize(Mean_Score = mean(Score, na.rm = TRUE))

# Create the ggplot bar graph
bar_plot <- ggplot(data_means) +
  geom_bar(aes(x = Ethnicity_Participant, y = Mean_Score, fill = Ethnicity_Participant), 
           stat = "identity", position = "dodge") +
  facet_wrap(~ Measure, scales = "free_y") +
  labs(
    title = "Ethnicity vs Mean Scores for Various Measures",
    x = "Ethnicity of Participant",
    y = "Mean Scores"
  ) +
  theme_minimal(base_size = 14) + # Increase base size for readability
  scale_fill_brewer(palette = "Set3") + # Colorful palette
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title = element_text(face = "bold"), # Bold axis titles
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5), # Bold title, centered
    strip.text = element_text(face = "bold"), # Bold facet labels
    legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 12)
  )

# Print the bar plot
print(bar_plot)

# Save the plot as a PNG image with APA style (high resolution for publication)
ggsave("ethnicity_vs_mean_scores_ggplot.png", plot = bar_plot, dpi = 300, width = 8, height = 6)

```



# correlation analysis

```{r,echo=TRUE,include=FALSE}
#| label: correlation-analysis
# Load necessary library
library(dplyr)
#Read the dataset
df <- read.csv("Data_Stigmatization_of HomelessIndividuals/cleaned_stigma_data.csv") # using the cleaned data set 

# Perform Pearson correlation test
cor.test(df$Social_Desirability_Bias, df$Mean_Help_Offering, method = "pearson")# both are numeric data
```

``` {r, echo=TRUE, include=True, results='asis'}
#| label: tbl-correlation-analysis-results
#| tbl-cap: Pearson Correlation Between Social Desirability Bias and Mean Help Offering
#| apa-note: The table presents the Pearson correlation test results, including the correlation coefficient, t-value, degrees of freedom, p-value, and confidence interval.

# Load necessary library
library(dplyr)

# Load the data
df <- read.csv("Data_Stigmatization_of HomelessIndividuals/cleaned_stigma_data.csv") # using the cleaned data set 

# tibble with the correlation results based on the provided values
cor_table <- tibble(
  Statistic = c("Correlation (r)", "t-value", "Degrees of Freedom", "p-value", "95% CI (Lower)", "95% CI (Upper)"),
  Value = c(
    round(-0.2752258, 3),  # Correlation
    round(-4.0688, 3),     # t-value
    202,                   # Degrees of Freedom
    format.pval(6.774e-05, digits = 3, eps = .001),  # p-value
    round(-0.3975658, 3),  # Lower bound of 95% CI
    round(-0.1432715, 3)   # Upper bound of 95% CI
  )
)

# Print the table
print(cor_table)

```

```{r}
#| label: scatter-plot-correlation
# Load necessary libraries
library(ggplot2)
library(dplyr)

# Load the cleaned data set
df <- read.csv("Data_Stigmatization_of HomelessIndividuals/cleaned_stigma_data.csv")

# Scatter Plot 
scatter_plot <- ggplot(df, aes(x = Social_Desirability_Bias, y = Mean_Help_Offering)) +
  geom_point(color = "blue") + 
  labs(title = "Scatter Plot: Social Desirability Bias vs Mean Help Offering",
       x = "Social Desirability Bias", 
       y = "Mean Help Offering") +
  theme_minimal()

# Print the scatter plot

print(scatter_plot)


```

# this help me build the scatter plot in the final paper. i did add more layers and made it better in final project 

# Participant demographics- what would have be
you can see the table in viewer in which 53% of sample identify as liberal 

```{r}
## Political affiliation 
#| label: tbl-political-affiliation
#| tbl-cap: Proportions of Political Affiliation Across Experimental Conditions.
#| apa-note: The table shows the proportions of participants' political affiliation across the experimental conditions. The total sample size is 215. Conditions can be found in the Measures section of the paper.

library(dplyr)
library(flextable)

# Load the data
df <- read.csv("Data_Stigmatization_of HomelessIndividuals/cleaned_stigma_data.csv")

# Convert relevant columns to factors
df$Political_Affiliation <- as.factor(df$Political_Affiliation)

# Calculate the total sample size
total_sample_size <- nrow(df)

# Create the proportion table for Political Affiliation
prop_table <- df %>%
  group_by(Political_Affiliation) %>%
  summarise(
    Proportion = n() / total_sample_size,
    .groups = "drop"
  )

# Add custom row names for political affiliation categories
prop_table$Political_Affiliation <- factor(prop_table$Political_Affiliation, 
                                           levels = c("1", "2", "3"), 
                                           labels = c("Liberal", "Moderate", "Conservative"))

# Display the table using flextable
prop_table |>
  flextable::flextable() |>
  flextable::theme_apa()

```


# more work with data

```{r}
# Install and load necessary libraries for data manipulation
# Uncomment if the packages are already installed- you do not need to install them again
# install.packages("tidyverse")
# install.packages("readr")
# install.packages("stringr")
# install.packages("forcats")

# Load the packages
library(tidyverse)  # package for data manipulation 
library(readr)      # For reading data
library(stringr)    # For string manipulation
library(forcats)    # For working with factors

# Function to calculate mean social distance score within the scale of 1-7. This is because the scale only goes up to 7
calculate_mean_score <- function(x, y, z) {
  mean_score <- mean(c(x, y, z), na.rm = TRUE)  # Compute mean, ignore NA values
  return(pmin(pmax(mean_score, 1), 7))  # score stays within the 1-7 scale
}

# Step 1: Load the original dataset and view the structure
playstigma_data <- read_csv("Data_Stigmatization_of HomelessIndividuals/cleaned_stigma_data.csv", show_col_types = FALSE)

# View first few rows of the original dataset
head(playstigma_data)

# View summary of the original dataset
summary(playstigma_data)

# Check the structure of the original dataset
str(playstigma_data)

# Step 2: Data cleaning and transformation pipeline
play_stigma_cleaned <- playstigma_data %>%
  
  # Convert columns to appropriate data types
  mutate(
    Race_Condition = as.factor(Race_Condition),  # Convert race condition to factor
    Diagnosis_Condition = as.factor(Diagnosis_Condition),  # Convert diagnosis condition to factor
    Condition_Type = as.factor(Condition_Type),  # Convert condition type to factor
    Social_Distance_Score_1 = as.numeric(Social_Distance_Score_1),  # Numeric conversion
    Social_Distance_Score_2 = as.numeric(Social_Distance_Score_2),  # Numeric conversion
    Social_Distance_Score_3 = as.numeric(Social_Distance_Score_3),  # Numeric conversion
    
    # Mean social distance score must stay within 1-7
    Mean_Social_Distance = calculate_mean_score(Social_Distance_Score_1, Social_Distance_Score_2, Social_Distance_Score_3),
    
    # Recode condition levels to reflect 6 distinct conditions
    Condition_Type = fct_recode(Condition_Type, 
                                "Black character/No mental illness" = "1", 
                                "Black character/Substance use disorder" = "2", 
                                "Black character/Schizophrenia" = "3", 
                                "White character/No mental illness" = "4", 
                                "White character/Substance use disorder" = "5", 
                                "White character/Schizophrenia" = "6"),
    
    # Group race conditions into top 3 most common categories
    Race_Condition = fct_lump_n(Race_Condition, n = 3),
    
    # Categorize social distance scores into High, Medium, Low
    Social_Distance_Category = case_when(
      Mean_Social_Distance >= 5 ~ "High",
      Mean_Social_Distance >= 3 & Mean_Social_Distance < 5 ~ "Medium",
      TRUE ~ "Low"
    ),
    
    # Identify whether condition is "Severe"
    Contains_Stigma = str_detect(as.character(Condition_Type), "Severe"),
    
    # Normalize scores between 0 and 1 (considering 1-7 scale)
    Normalized_Score = round((Mean_Social_Distance - 1) / 6, 2)
  ) %>%
  
  # Remove rows with missing values and duplicates
  drop_na() %>%
  distinct()

# Step 3: View the cleaned data after transformation
# View first few rows after transformation
head(play_stigma_cleaned)

# View summary of the cleaned dataset
summary(play_stigma_cleaned)

# Check the structure of the cleaned dataset
str(play_stigma_cleaned)

# Step 4: Inspect changes made during transformation
# Check which conditions were recoded and the frequencies of each category
table(play_stigma_cleaned$Condition_Type)

# Check the number of unique values in key columns (e.g., Race_Condition, Diagnosis_Condition)
table(play_stigma_cleaned$Race_Condition)
table(play_stigma_cleaned$Diagnosis_Condition)

# Step 5: Check the categorization of social distance (High, Medium, Low)
table(play_stigma_cleaned$Social_Distance_Category)

# Step 6: View the normalized scores to ensure the scaling is correct
summary(play_stigma_cleaned$Normalized_Score)

# I did not want to print new data file as it was not needed for the paper if i did i would of used the write.csv function if i wanted to save it  or print function if i wanted to see it. 

```





